{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92973e83-2782-4906-a873-f7f826fd6de0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#1introduction\n",
    "!pip install gensim\n",
    "!pip install pyLDAvis\n",
    "!pip install nltk\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import pandas\n",
    "pandas.set_option('display.max_colwidth', None)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "\n",
    "#Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim import models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "\n",
    "#spacy\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#vis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd684d-cb3b-46a2-b7d1-6b93d44c08bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hours(minDate:str,maxDate:str)-> (str,str):\n",
    "\tminDate = minDate + \"00:00:00\"\n",
    "\tmaxDate = maxDate + \"23:59:59\"\n",
    "\n",
    "\treturn minDate,maxDate\n",
    "\n",
    "def get_comments(originPath:str,minDate:str = None,maxDate:str = None,versions = None) -> pandas.DataFrame:\n",
    "\t\n",
    "\tcommentsFile = pandas.read_csv(originPath)\n",
    "\n",
    "\tif minDate != None and maxDate != None:\n",
    "\t\tminDate,maxDate = add_hours(minDate,maxDate)\n",
    "\n",
    "\tfor i in range(0, len(commentsFile)):\n",
    "\t\tif commentsFile['date'][i] < minDate or commentsFile['date'][i] > maxDate or commentsFile['version'][i] not in versions:\n",
    "\t\t\t#print(\"droped\",commentsFile['version'][i])\n",
    "\t\t\tcommentsFile = commentsFile.drop([i])\n",
    "\treturn commentsFile\n",
    "\n",
    "def lemmatization(texts, allowed_postags):\n",
    "    nlp = spacy.load(\"pt_core_news_sm\")\n",
    "    texts_out = []\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_postags:\n",
    "                new_text.append(token.lemma_)\n",
    "        final = \" \".join(new_text)\n",
    "        texts_out.append(final)\n",
    "    return (texts_out)\n",
    "\n",
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e16d5c-cf72-4adf-b508-efdd1ef60f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = get_comments(\"./General_Data.csv\",\"2021-01-01\",\"2021-10-20\",\"3.0.0\")\n",
    "data = database['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d8231-c23e-47fd-bab1-2ec79fd1c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = database[database['score'] == 1]\n",
    "data = score1['content'] # selectionando apenas os coment치rios com nota = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e2587d-6350-4211-80e8-3ebfedeb14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_texts = lemmatization(data, [\"NOUN\", \"VERB\"])\n",
    "print (lemmatized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8543e93-4fae-4578-a858-6f692d4149d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = gen_words(lemmatized_texts)\n",
    "print (data_words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa1f6dd-8452-4fa3-92c3-42bba7bee064",
   "metadata": {},
   "source": [
    "# Extraindo t칩picos a partir de palavras unit치rias (1-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8086c-e68f-4c8d-96cc-00f29bc06dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "corpus = []\n",
    "for text in data_words:\n",
    "    new = id2word.doc2bow(text)\n",
    "    corpus.append(new)\n",
    "\n",
    "print (corpus[0])\n",
    "\n",
    "word = id2word[[7][:1][0]]\n",
    "print (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0833f38-2ace-403b-aa07-7144f1bb98d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10,\n",
    "                                           random_state=1000,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1031937f-8fa5-4f27-94e4-7c7621af5e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds=\"mmds\", R=100)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a10bb0-c5c2-4317-b29d-e8780da9c154",
   "metadata": {},
   "source": [
    "# Extraindo t칩picos em n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9541ba4a-c925-49cb-aa91-44e15a5784eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3 #qtde de ngrams\n",
    "print(data_words[0])\n",
    "ngrams = []\n",
    "for sentence in data_words:\n",
    "    ngrams_temp = []\n",
    "    tokens = list(sentence)\n",
    "    for i in range(0,len(tokens)-(N-1)):\n",
    "        new_text = tokens[i]\n",
    "        for k in range(1,N):\n",
    "            new_text = new_text + '_' + tokens[i+k]\n",
    "        ngrams_temp.append(new_text)\n",
    "    ngrams.append(ngrams_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c54db4b-b349-46bf-9b97-7e0862533ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ngrams[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36431995-0f79-4e34-bdd3-46c9b371ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2ngram = corpora.Dictionary(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e177d037-98d9-4c75-a6eb-402285bdff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_ngram = []\n",
    "for text in ngrams:\n",
    "    new = id2ngram.doc2bow(text)\n",
    "    corpus_ngram.append(new)\n",
    "\n",
    "print (corpus_ngram[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a91fe2e-b1ef-45c4-819b-c9f24afcfdb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lda_model_ngram = gensim.models.ldamodel.LdaModel(corpus=corpus_ngram,\n",
    "                                           id2word=id2ngram,\n",
    "                                           num_topics=10,\n",
    "                                           random_state=1000,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61a15f9-4104-4e7d-bc7a-ce2a3171ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model_ngram, corpus_ngram, id2ngram, mds=\"mmds\", R=100)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c9a1f-34cf-45e8-a2d0-6b9d828d203e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
